{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to increase contrast in the labels by assigning diffrent colors.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adjust_contrast(image, rgb_codes, new_values):\n",
    "    \"\"\"Adjust the contrast of an image based on new values for the RGB codes.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): Input image.\n",
    "        rgb_codes (list): List of original RGB codes.\n",
    "        new_values (list): List of new RGB values for better contrast.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Image with adjusted contrast.\n",
    "    \"\"\"\n",
    "    # Create a mapping from original to new values\n",
    "    mapping = {old: new for old, new in zip(rgb_codes, new_values)}\n",
    "    \n",
    "    # Create an output image\n",
    "    output_image = np.zeros_like(image)\n",
    "    \n",
    "    # Apply the mapping\n",
    "    for old, new in mapping.items():\n",
    "        mask = (image == old).all(axis=-1)\n",
    "        output_image[mask] = new\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "def process_folder(src_folder, dest_folder, rgb_codes, new_values):\n",
    "    \"\"\"Process all images in a folder to adjust their contrast and save them.\n",
    "    \n",
    "    Args:\n",
    "        src_folder (str): Source folder containing the images.\n",
    "        dest_folder (str): Destination folder to save the processed images.\n",
    "        rgb_codes (list): List of original RGB codes.\n",
    "        new_values (list): List of new RGB values for better contrast.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    \n",
    "    for filename in os.listdir(src_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "            # Read the image\n",
    "            src_path = os.path.join(src_folder, filename)\n",
    "            image = cv2.imread(src_path)\n",
    "            \n",
    "            # Adjust the contrast\n",
    "            adjusted_image = adjust_contrast(image, rgb_codes, new_values)\n",
    "            \n",
    "            # Save the adjusted image\n",
    "            dest_path = os.path.join(dest_folder, filename)\n",
    "            cv2.imwrite(dest_path, adjusted_image)\n",
    "\n",
    "# Original RGB codes and new values for better contrast\n",
    "rgb_codes = [(i, i, i) for i in range(7)]\n",
    "new_values = [(int((255/7) * i), int((255/7) * i), int((255/7) * i)) for i in range(7)]\n",
    "\n",
    "# Example usage for train folder\n",
    "src_folder = r'D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\\train\\labels'\n",
    "dest_folder = r'D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\\train\\labels_c'\n",
    "\n",
    "process_folder(src_folder, dest_folder, rgb_codes, new_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for the val folder\n",
    "src_folder = r'D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\\val\\labels'\n",
    "dest_folder = r'D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\\val\\labels_c'\n",
    "\n",
    "process_folder(src_folder, dest_folder, rgb_codes, new_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Fit the model .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \t122 - 122\n",
      "Valid: \t137 - 137\n",
      "Test: \t137 - 137\n",
      "Shape of train_x: 122\n",
      "Shape of train_y: 122\n",
      "Shape of valid_x: 137\n",
      "Shape of valid_y: 137\n",
      "Shape of test_x: 137\n",
      "Shape of test_y: 137\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.3339 - accuracy: 0.6070\n",
      "Epoch 1: val_loss improved from inf to 1.11673, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HamzaKhalid\\envs\\heart\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 53s 5s/step - loss: 1.3339 - accuracy: 0.6070 - val_loss: 1.1167 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.9976\n",
      "Epoch 2: val_loss improved from 1.11673 to 0.70043, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.3755 - accuracy: 0.9976 - val_loss: 0.7004 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9999\n",
      "Epoch 3: val_loss improved from 0.70043 to 0.49704, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n",
      "8/8 [==============================] - 36s 5s/step - loss: 0.1626 - accuracy: 0.9999 - val_loss: 0.4970 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 4: val_loss improved from 0.49704 to 0.37971, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 5: val_loss improved from 0.37971 to 0.30050, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n",
      "8/8 [==============================] - 35s 5s/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 6: val_loss improved from 0.30050 to 0.24304, saving model to D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\\model.h5\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 1.0000 - lr: 0.1000\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Suppress the specific warning about deprecated function\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "3\n",
    "from unetr_2d import build_unetr_2d\n",
    "\n",
    "\n",
    "\"\"\" UNETR  Configration \"\"\"\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 256\n",
    "cf[\"num_classes\"] = 7\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12\n",
    "cf[\"hidden_dim\"] = 128\n",
    "cf[\"mlp_dim\"] = 32\n",
    "cf[\"num_heads\"] = 6\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    ")\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.png\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.png\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.png\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    \"\"\" Processing to patches \"\"\"\n",
    "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n",
    "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "\n",
    "################# change ##############\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    mask = mask.astype(np.int32)\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        y = tf.one_hot(y, cf[\"num_classes\"])\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape(cf[\"flat_patches_shape\"])\n",
    "    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], cf[\"num_classes\"]])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
    "    return ds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 16\n",
    "    lr = 0.1\n",
    "    num_epochs = 100\n",
    "    model_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\", \"model.h5\")\n",
    "    csv_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\", \"log.csv\")\n",
    "\n",
    "    \"\"\" RGB Code and Classes \"\"\"\n",
    "    rgb_codes = [\n",
    "        (0, 0, 0), (36, 36, 36), (72, 72, 72), (109, 109, 109), (145, 145, 145), (182, 182, 182), (218, 218, 218)\n",
    "    ]\n",
    "\n",
    "    classes = [\n",
    "        \"background\",\"head\",\"acrosome\",\"non-acrosome\",\"midpiece\",\"tail\",\"noise\"\n",
    "    ]\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\"\n",
    "    #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y)= load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "\n",
    "######### the error was in the load_data function where the type of images was set to jpg intead of png in our case....\n",
    "    print(f\"Shape of train_x: {len(train_x)}\")\n",
    "    print(f\"Shape of train_y: {len(train_y)}\")\n",
    "    print(f\"Shape of valid_x: {len(valid_x)}\")\n",
    "    print(f\"Shape of valid_y: {len(valid_y)}\")\n",
    "    print(f\"Shape of test_x: {len(test_x)}\")\n",
    "    print(f\"Shape of test_y: {len(test_y)}\")\n",
    "\n",
    "################################################################################################################\n",
    "###########################################   Model Training Begins  ###########################################\n",
    "################################################################################################################\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "   \n",
    "\n",
    "    model = build_unetr_2d(cf)\n",
    "    # Compiling the model with categorical crossentropy loss, SGD optimizer, and accuracy metric\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=False, verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=callbacks\n",
    ")\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to fit model using cuda on local device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "\n",
    "from unetr_2d import build_unetr_2d\n",
    "\n",
    "\"\"\" UNETR  Configration \"\"\"\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 256\n",
    "cf[\"num_classes\"] = 7\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12\n",
    "cf[\"hidden_dim\"] = 128\n",
    "cf[\"mlp_dim\"] = 32\n",
    "cf[\"num_heads\"] = 6\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    ")\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.png\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.png\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels_c\", \"*.png\")))\n",
    "    \n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.png\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    \"\"\" Processing to patches \"\"\"\n",
    "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n",
    "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    mask = mask.astype(np.int32)\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        y = tf.one_hot(y, cf[\"num_classes\"])\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape(cf[\"flat_patches_shape\"])\n",
    "    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], cf[\"num_classes\"]])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
    "    return ds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    # create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 16\n",
    "    lr = 0.1\n",
    "    num_epochs = 100\n",
    "    model_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\", \"model.h5\")\n",
    "    csv_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\", \"log.csv\")\n",
    "\n",
    "    \"\"\" RGB Code and Classes \"\"\"\n",
    "    rgb_codes = [\n",
    "        (0, 0, 0), (36, 36, 36), (72, 72, 72), (109, 109, 109), (145, 145, 145), (182, 182, 182), (218, 218, 218)\n",
    "    ]\n",
    "\n",
    "    classes = [\n",
    "        \"background\",\"head\",\"acrosome\",\"non-acrosome\",\"midpiece\",\"tail\",\"noise\"\n",
    "    ]\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = build_unetr_2d(cf)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=valid_dataset,\n",
    "            callbacks=callbacks\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model's output :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 170\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Save the results \"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m save_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mJIO Institute\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCapstone\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCapstone_V2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mID_code_UnetR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMulticlass-Image-Segmentation-using-UNETR-in-TensorFlow\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 61\u001b[0m, in \u001b[0;36msave_results\u001b[1;34m(image_x, mask, pred, save_image_path)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_results\u001b[39m(image_x, mask, pred, save_image_path):\n\u001b[0;32m     60\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mgrayscale_to_rgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgb_codes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m     pred \u001b[38;5;241m=\u001b[39m grayscale_to_rgb(pred, rgb_codes)\n",
      "Cell \u001b[1;32mIn[21], line 40\u001b[0m, in \u001b[0;36mgrayscale_to_rgb\u001b[1;34m(mask, rgb_codes)\u001b[0m\n\u001b[0;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pixel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mask\u001b[38;5;241m.\u001b[39mflatten()):\n\u001b[1;32m---> 40\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrgb_codes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(output, (h, w, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from patchify import patchify\n",
    "\n",
    "\n",
    "from unetr_2d import build_unetr_2d\n",
    "\n",
    "from train import load_dataset, create_dir\n",
    "\n",
    "\"\"\" UNETR  Configration \"\"\"\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 256\n",
    "cf[\"num_classes\"] = 7\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12\n",
    "cf[\"hidden_dim\"] = 128\n",
    "cf[\"mlp_dim\"] = 32\n",
    "cf[\"num_heads\"] = 6\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    ")\n",
    "\n",
    "def grayscale_to_rgb(mask, rgb_codes):\n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    mask = mask.astype(np.int32)\n",
    "    output = []\n",
    "\n",
    "    for i, pixel in enumerate(mask.flatten()):\n",
    "        output.append(rgb_codes[pixel])\n",
    "\n",
    "    output = np.reshape(output, (h, w, 3))\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.png\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.png\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.png\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"labels_c\", \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "\n",
    "def save_results(image_x, mask, pred, save_image_path):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = grayscale_to_rgb(mask, rgb_codes)\n",
    "\n",
    "    pred = np.expand_dims(pred, axis=-1)\n",
    "    pred = grayscale_to_rgb(pred, rgb_codes)\n",
    "\n",
    "    line = np.ones((image_x.shape[0], 10, 3)) * 255\n",
    "\n",
    "    cat_images = np.concatenate([image_x, line, mask, line, pred], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(f\"results\")\n",
    "\n",
    "    \"\"\" Load the model \"\"\"\n",
    "    model_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\files\", \"model.h5\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    \"\"\" RGB Code and Classes \"\"\"\n",
    "    rgb_codes = [\n",
    "        (0, 0, 0), (36, 36, 36), (72, 72, 72), (109, 109, 109), (145, 145, 145), (182, 182, 182), (218, 218, 218)\n",
    "    ]\n",
    "\n",
    "    classes = [\n",
    "        \"background\", \"head\" ,\"acrosome\" ,\"non-acrosome\" ,\"midpiece\" ,\"tail\" ,\"noise\"\n",
    "    ]\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\casa_data_new\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "    \n",
    "\n",
    "    ## as we donot currently have a test data directory .... we're simply using the valid directory as the test directory !!\n",
    "\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    \n",
    "    ######################################################### new code that  multiplies pred by 225 #################################################################\n",
    "\n",
    "    # for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "    #     \"\"\" Extracting the name \"\"\"\n",
    "    #     name = os.path.basename(x).split(\".\")[0]\n",
    "\n",
    "    #     \"\"\" Reading the image \"\"\"\n",
    "    #     image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    #     x = image / 255.0\n",
    "\n",
    "    #     patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    #     patches = patchify(x, patch_shape, cf[\"patch_size\"])\n",
    "    #     patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    #     patches = patches.astype(np.float32) #[...]\n",
    "    #     patches = np.expand_dims(patches, axis=0) # [1, ...]\n",
    "\n",
    "    #     \"\"\" Read Mask \"\"\"\n",
    "    #     mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    #     mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    #     mask = mask.astype(np.int32)\n",
    "\n",
    "    #     \"\"\" Prediction \"\"\"\n",
    "    #     pred = model.predict(patches, verbose=0)[0]\n",
    "    #     pred = np.argmax(pred, axis=-1) ## [0.1, 0.2, 0.1, 0.6] -> 3\n",
    "    #     pred = pred.astype(np.int32)\n",
    "\n",
    "    #     \"\"\" Scale the predicted values back to 0-255 \"\"\"\n",
    "    #     pred = pred * 255\n",
    "    #     pred = np.clip(pred, 0, 255)  # Ensure the values are within 0-255\n",
    "    #     pred = pred.astype(np.uint8)\n",
    "\n",
    "    #     \"\"\" Save the results \"\"\"\n",
    "    #     save_image_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\results\",f\"{name}.png\")\n",
    "    #     save_results(image, mask, pred, save_image_path)\n",
    "    \n",
    "    \n",
    "    ######################################################### old code that wasn't multiplying by 225 #################################################################\n",
    "    \n",
    "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading the image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "        x = image / 255.0\n",
    "\n",
    "        patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "        patches = patchify(x, patch_shape, cf[\"patch_size\"])\n",
    "        patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "        patches = patches.astype(np.float32) #[...]\n",
    "        patches = np.expand_dims(patches, axis=0) # [1, ...]\n",
    "\n",
    "        \"\"\" Read Mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "        mask = mask.astype(np.int32)\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "        pred = model.predict(patches, verbose=0)[0]\n",
    "        pred = np.argmax(pred, axis=-1) ## [0.1, 0.2, 0.1, 0.6] -> 3\n",
    "        pred = pred.astype(np.int32)\n",
    "\n",
    "        \"\"\" Save the results \"\"\"\n",
    "        save_image_path = os.path.join(r\"D:\\JIO Institute\\Capstone\\Capstone_V2\\ID_code_UnetR\\Multiclass-Image-Segmentation-using-UNETR-in-TensorFlow\\results\",f\"{name}.png\")\n",
    "        save_results(image, mask, pred, save_image_path)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
